{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/datastaxdevs_banner.png\" width=\"600\" height=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm 1: K-Means Clustering\n",
    "------\n",
    "<img src=\"images/socialMedia.jpeg\" width=\"400\" height=\"500\">\n",
    "\n",
    "#### Dataset: https://archive.ics.uci.edu/ml/datasets/Facebook+Live+Sellers+in+Thailand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are we trying to learn from this dataset? \n",
    "\n",
    "### Can K-Means be used to do social media analysis?\n",
    "### Can we group together different types of media by the reaction they received?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas\n",
    "from pyspark.sql import SparkSession\n",
    "#\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.clustering import KMeans\n",
    "#\n",
    "from cassandra.cluster import Cluster\n",
    "from cassandra.auth import PlainTextAuthProvider\n",
    "#\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "from tools import showDF, examineCassandraTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read .env file for connection params\n",
    "dotenv_file = find_dotenv('.env')\n",
    "load_dotenv(dotenv_file)\n",
    "astraUsername = os.environ['ASTRA_DB_CLIENT_ID']\n",
    "astraPassword = os.environ['ASTRA_DB_CLIENT_SECRET']\n",
    "astraSecureConnect = os.environ['ASTRA_DB_SECURE_BUNDLE_PATH']\n",
    "astraKeyspace = os.environ['ASTRA_DB_KEYSPACE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect input data: Table(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Cassandra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_config = {\n",
    "    'secure_connect_bundle': '/home/jovyan/' + astraSecureConnect\n",
    "}\n",
    "auth_provider = PlainTextAuthProvider(username=astraUsername, password=astraPassword)\n",
    "cluster = Cluster(cloud=cloud_config, auth_provider=auth_provider)\n",
    "session = cluster.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connectivity test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = session.execute('SELECT key, cluster_name, data_center FROM system.local;')\n",
    "local = rows.one()\n",
    "if local:\n",
    "    print('    ** Connected to cluster \\'%s\\' at data center \\'%s\\' **' % (\n",
    "        local.cluster_name,\n",
    "        local.data_center,\n",
    "    ))\n",
    "else:\n",
    "\n",
    "    print('Error: could not read \\'system.local\\' table!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set keyspace "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.set_keyspace(astraKeyspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine table `socialmedia` (structure and contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(examineCassandraTable(session, astraKeyspace, 'socialmedia'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What do these 11 columns represent: \n",
    "\n",
    "* **Status_id**: Unique key created for each row\n",
    "* **Num Reactions**\n",
    "* **Num Comments**\n",
    "* **Num Shares**\n",
    "* **Num Likes**\n",
    "* **Num Loves**\n",
    "* **Num Wows**\n",
    "* **Num Hahas**\n",
    "* **Num Sads**\n",
    "* **Num Angrys**\n",
    "* **Social Type**: Picture or Video\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/getTheLikes.png\" width=\"300\" height=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning with Apache Cassandra & Apache Spark\n",
    "<img src=\"images/sparklogo.png\" width=\"150\" height=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Spark session that is connected to the database. From there load each table into a Spark Dataframe and take a count of the number of rows in each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName('demo') \\\n",
    "    .master('local') \\\n",
    "    .config( \\\n",
    "        'spark.cassandra.connection.config.cloud.path', \\\n",
    "        'file:' + '/home/jovyan/' + astraSecureConnect) \\\n",
    "    .config('spark.cassandra.auth.username', astraUsername) \\\n",
    "    .config('spark.cassandra.auth.password', astraPassword) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "socialDF = spark \\\n",
    "    .read \\\n",
    "    .format('org.apache.spark.sql.cassandra') \\\n",
    "    .options(table='socialmedia', keyspace=astraKeyspace) \\\n",
    "    .load()\n",
    "\n",
    "print ('Table Row Count:')\n",
    "print (socialDF.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showDF(socialDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: when working with `STRING` data types you need to turn those `STRING` types into `FLOAT` types, thereby creating labels that **K-means** and **Apache Spark** can understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelIndexer = StringIndexer(inputCol='social_type', outputCol='label', handleInvalid='keep')\n",
    "training = labelIndexer.fit(socialDF).transform(socialDF)\n",
    "\n",
    "showDF(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showDF(training.select('social_type', 'label'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training.groupBy('social_type').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's visualize this data with a scatter plot:\n",
    "\n",
    "- The x axis will be number of likes \n",
    "- The y axis will be number of comments\n",
    "- The color of the dot will be assigned based on its \"cluster\" Photo or Video\n",
    "\n",
    "Note: These attributes are what might be a strong attributes to finding clusters (Photo - Video)\n",
    "Note 1: Must move to a Pandas dataframe to do this visualization (be aware! This can't always be done as is, depending on your data size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smPanda = training.toPandas()\n",
    "smPanda.plot.scatter(x='num_likes', y='num_comments', c='label', figsize=(12,8), colormap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two clusters here: Yellow = Video  and Purple = Pictures\n",
    "\n",
    "From what we can see from these two attributes that Videos get less likes but more comments, while Pictures get less comments but more likes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's see if K-Means can give us the same clustering\n",
    "\n",
    "K-Means clustering is a simple unsupervised learning algorithm that is used to solve clustering problems. K-Means is very simple, but very powerful even on large datasets. It requires that all the input columns be vectorized. \n",
    "\n",
    "https://spark.apache.org/docs/latest/ml-features.html#vectorassembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols=['num_likes', 'num_comments'],\n",
    "    outputCol='features',\n",
    ")\n",
    "\n",
    "trainingData = assembler.transform(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We need to set the K for K-Means which we will set at 2. One of the downsides of unsupervised learning is that we normally will not have predefined clusters (well, in this case \"secretly we do\"). K-Means will happily split the data into as many clusters as you set. \n",
    "\n",
    "### First we will generate the model and then make predictions based on that model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans().setK(2).setSeed(1)\n",
    "model = kmeans.fit(trainingData)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.transform(trainingData)\n",
    "\n",
    "showDF(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this case because we are actually performing surpervised learnings (since we do have the cluster labels) we can do some comparisons to see if our predictions are correct. \n",
    "\n",
    "Here we simply compare the counts for each cluster for the labels vs. the prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.groupBy('prediction').count().show()\n",
    "training.groupBy('social_type').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's create another scatter plot to see if this lines up with our orignal scatter plot. \n",
    "\n",
    "Everything is the same except now our dots will represent the color of the prediction (instead of the orginal cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df = predictions.toPandas()\n",
    "car_df.plot.scatter(x='num_likes', y='num_comments', c='prediction', figsize=(12,8), colormap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Videos are represented in yellow and pictures in purple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Means struggles when you add many variables, so adding more variables is unlikely to help. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Remember: Data Science/Analytics is an iterative process! It's a science! Hypothesis, test, analysis, and loop again!_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example model usage\n",
    "\n",
    "_Note: in real life, your input is probably massive (as opposed to a single row); also, it is likely read from the database._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_socialmedia_cluster(**kwargs):\n",
    "    input_df = pandas.DataFrame([kwargs])\n",
    "    spark_input = spark.createDataFrame(input_df)\n",
    "    spark_with_features = assembler.transform(spark_input)\n",
    "    predicted = model.transform(spark_with_features)\n",
    "    collected = predicted.collect()\n",
    "    #\n",
    "    return {\n",
    "        'prediction': collected[0].prediction,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_socialmedia_cluster(\n",
    "    num_likes=120,\n",
    "    num_comments=3200,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stop the Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
