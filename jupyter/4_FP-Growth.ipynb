{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/datastaxdevs_banner.png\" width=\"600\" height=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm 4: FP-Growth\n",
    "------\n",
    "<img src=\"images/pixarMovies.jpg\" width=\"500\" height=\"500\">\n",
    "\n",
    "\n",
    "#### Dataset: https://grouplens.org/datasets/movielens/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are we trying to learn from this dataset? \n",
    "\n",
    "### Can FP-Growth be used to determine movie recommendations?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas\n",
    "from pyspark.sql import SparkSession\n",
    "#\n",
    "from operator import itemgetter\n",
    "#\n",
    "from pyspark.sql.functions import collect_set\n",
    "from pyspark.ml.fpm import FPGrowth\n",
    "from pyspark.sql.functions import array_contains, col\n",
    "#\n",
    "from cassandra.cluster import Cluster\n",
    "from cassandra.auth import PlainTextAuthProvider\n",
    "#\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "from tools import showDF, examineCassandraTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read .env file for connection params\n",
    "dotenv_file = find_dotenv('.env')\n",
    "load_dotenv(dotenv_file)\n",
    "astraUsername = os.environ['ASTRA_DB_CLIENT_ID']\n",
    "astraPassword = os.environ['ASTRA_DB_CLIENT_SECRET']\n",
    "astraSecureConnect = os.environ['ASTRA_DB_SECURE_BUNDLE_PATH']\n",
    "astraKeyspace = os.environ['ASTRA_DB_KEYSPACE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect input data: Table(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_config = {\n",
    "    'secure_connect_bundle': '/home/jovyan/' + astraSecureConnect\n",
    "}\n",
    "auth_provider = PlainTextAuthProvider(username=astraUsername, password=astraPassword)\n",
    "cluster = Cluster(cloud=cloud_config, auth_provider=auth_provider)\n",
    "session = cluster.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set keyspace "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.set_keyspace(astraKeyspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine table `movies` (structure and contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(examineCassandraTable(session, astraKeyspace, 'movies'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine table `movieratings` (structure and contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(examineCassandraTable(session, astraKeyspace, 'movieratings'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column meaning:\n",
    "\n",
    "#### `movies`\n",
    "\n",
    "* **Movieid**\n",
    "* **Title**\n",
    "* **Genres**\n",
    "\n",
    "#### `movieratings`\n",
    "\n",
    "* **UserId**\n",
    "* **MovieId**\n",
    "* **Rating**\n",
    "* **Timestamp**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/bttf3.jpg\" width=\"500\" height=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning with Apache Cassandra & Apache Spark\n",
    "<img src=\"images/sparklogo.png\" width=\"150\" height=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Spark session that is connected to the database. From there load each table into a Spark Dataframe and take a count of the number of rows in each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName('demo') \\\n",
    "    .master('local') \\\n",
    "    .config( \\\n",
    "        'spark.cassandra.connection.config.cloud.path', \\\n",
    "        'file:' + '/home/jovyan/' + astraSecureConnect) \\\n",
    "    .config('spark.cassandra.auth.username', astraUsername) \\\n",
    "    .config('spark.cassandra.auth.password', astraPassword) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "movieDF = spark \\\n",
    "    .read \\\n",
    "    .format('org.apache.spark.sql.cassandra') \\\n",
    "    .options(table='movieratings', keyspace=astraKeyspace) \\\n",
    "    .load()\n",
    "\n",
    "print ('Table Row Count:')\n",
    "print (movieDF.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showDF(movieDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This dataset is not in the format we need.\n",
    "\n",
    "### Let's make it into _\"one row per user with a list of movies the user reviewed\"_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove the timestamp column since we will not be using that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newMovieDF = movieDF.drop('timestamp')\n",
    "showDF(newMovieDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Before we collect the set of movies for each user let's filter out any movies they rated less or equal to 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newestMovies = newMovieDF.filter('rating > 3')\n",
    "showDF(newestMovies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GroupBy the user id and create a collection set of all the movies they have rated and seen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_user = newestMovies.groupBy('userid').agg(collect_set('movieid').alias('moviesRated'))\n",
    "group_user.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's rename the column with movies to `items`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = group_user.withColumnRenamed('moviesRated', 'items')\n",
    "showDF(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select('userid').distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FP-Growth for  Recommendations\n",
    "#### Use Apache Spark MLlib with FPGrowth to find Recommendation s\n",
    "#### https://spark.apache.org/docs/latest/ml-frequent-pattern-mining.html\n",
    "#### https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.fpm.FPGrowth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpGrowth = FPGrowth(itemsCol='items', minSupport=0.1, minConfidence=0.2)\n",
    "model = fpGrowth.fit(df)\n",
    "recommendDF=model.transform(df)\n",
    "recommendDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display frequent itemsets.\n",
    "model.freqItemsets.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display generated association rules.\n",
    "dfAssociation = model.associationRules\n",
    "dfAssociation.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have watched (and liked) an `antecedent` movie, then we'll recommend the corresponding `consequent` ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('If you liked these movies: ', end='')\n",
    "print(list(dfAssociation.select('antecedent').first()))\n",
    "print('Then you will like this movie: ', end='')\n",
    "print(list(dfAssociation.select('consequent').first()))\n",
    "\n",
    "movieYouLike = list(dfAssociation.select('antecedent').first())\n",
    "movieToRecommend=list(dfAssociation.select('consequent').first())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's resolve `movieid` to actual names with the `movies` table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolveMovie(movie_id):\n",
    "    query = 'SELECT title FROM movies WHERE movieid=%s;'\n",
    "    movie_row = session.execute(query, (movie_id,)).one()\n",
    "    print('    [movieid=%s] => \"%s\"' % (movie_id, movie_row.title))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If you liked these..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Antecedents:')\n",
    "resolveMovie(movieYouLike[0][0])\n",
    "resolveMovie(movieYouLike[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Then you will like this movie ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Consequent:')\n",
    "resolveMovie(movieToRecommend[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example model usage\n",
    "\n",
    "_Note: in real life, your input is probably massive (as opposed to a single row); also, it is likely read from the database._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def associate_movie_by_id(input_movie_id):\n",
    "    consequent_counts = dfAssociation\\\n",
    "        .filter(array_contains(col('antecedent'), input_movie_id))\\\n",
    "        .select('consequent')\\\n",
    "        .rdd\\\n",
    "        .flatMap(lambda x: x)\\\n",
    "        .flatMap(lambda x: x)\\\n",
    "        .groupBy(lambda x: x)\\\n",
    "        .map(lambda xy: (xy[0], len(xy[1])))\\\n",
    "        .collect()\n",
    "    if len(consequent_counts):\n",
    "        return sorted(consequent_counts, key=itemgetter(1), reverse=True)[0][0]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appreciated_movie = 527\n",
    "recommended_movie = associate_movie_by_id(input_movie_id=appreciated_movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Example: user liked this:')\n",
    "resolveMovie(appreciated_movie)\n",
    "print('Then we\\'ll recomment this:')\n",
    "resolveMovie(recommended_movie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stop the Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
