{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo 3: Random Forest and DataStax Analytics\n",
    "------\n",
    "<img src=\"images/drinkWine.jpeg\" width=\"300\" height=\"500\">\n",
    "\n",
    "\n",
    "#### Dataset: https://archive.ics.uci.edu/ml/datasets/Wine+Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are we trying to learn from this dataset? \n",
    "\n",
    "# QUESTION: Can Random Forest be used to classify a wineâ€™s rating score by its attributes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import cassandra\n",
    "import pyspark\n",
    "import re\n",
    "import os\n",
    "import random\n",
    "from random import randint, randrange\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Markdown\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorAssembler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read .env file for connection params\n",
    "dotenv_file = find_dotenv('.env')\n",
    "load_dotenv(dotenv_file)\n",
    "astraUsername = os.environ[\"ASTRA_DB_CLIENT_ID\"]\n",
    "astraPassword = os.environ[\"ASTRA_DB_CLIENT_SECRET\"]\n",
    "astraSecureConnect = os.environ[\"ASTRA_DB_SECURE_BUNDLE_PATH\"]\n",
    "astraKeyspace = os.environ[\"ASTRA_DB_KEYSPACE\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper function to have nicer formatting of Spark DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper for pretty formatting for Spark DataFrames\n",
    "def showDF(df, limitRows =  5, truncate = True):\n",
    "    if(truncate):\n",
    "        pandas.set_option('display.max_colwidth', 50)\n",
    "    else:\n",
    "        pandas.set_option('display.max_colwidth', None)\n",
    "    pandas.set_option('display.max_rows', limitRows)\n",
    "    display(df.limit(limitRows).toPandas())\n",
    "    pandas.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Tables and Loading Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Cassandra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cassandra.cluster import Cluster\n",
    "from cassandra.auth import PlainTextAuthProvider\n",
    "\n",
    "cloud_config = {\n",
    "    'secure_connect_bundle': '/home/jovyan/' + astraSecureConnect\n",
    "}\n",
    "auth_provider = PlainTextAuthProvider(username=astraUsername, password=astraPassword)\n",
    "cluster = Cluster(cloud=cloud_config, auth_provider=auth_provider)\n",
    "session = cluster.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set keyspace "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.set_keyspace(astraKeyspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create table called `wines`. Our PRIMARY will be a unique key (wineid) we generate for each row.  This will have two datasets \"white\" and \"red\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"CREATE TABLE IF NOT EXISTS wines \\\n",
    "#                                    (wineid int, fixedAcidity float, volatileAcidity float, citricAcid float, sugar float, \\\n",
    "#                                    chlorides float, freeSulfur float, totalSulfur float, density float, ph float, \\\n",
    "#                                    sulphates float, alcohol float, quality float, \\\n",
    "#                                    PRIMARY KEY (wineid))\"\n",
    "# session.execute(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What do these of these 12 columns represent: \n",
    "\n",
    "* **Fixed acidity**\n",
    "* **Volatile acidity**\n",
    "* **Citric Acid**\n",
    "* **Residual Sugar** \n",
    "* **Chlorides**\n",
    "* **Free sulfur dioxide**     \n",
    "* **Total sulfur dioxide**\n",
    "* **Density** \n",
    "* **pH**\n",
    "* **Sulphates**\n",
    "* **Alcohol**\n",
    "* **Quality**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/whiteAndRed.jpeg\" width=\"300\" height=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning with Apache Cassandra and Apache Spark\n",
    "<img src=\"images/sparklogo.png\" width=\"150\" height=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a spark session that is connected to the database. From there load each table into a Spark Dataframe and take a count of the number of rows in each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName('demo') \\\n",
    "    .master(\"local\") \\\n",
    "    .config( \\\n",
    "        \"spark.cassandra.connection.config.cloud.path\", \\\n",
    "        \"file:\" + '/home/jovyan/' + astraSecureConnect) \\\n",
    "    .config(\"spark.cassandra.auth.username\", astraUsername) \\\n",
    "    .config(\"spark.cassandra.auth.password\", astraPassword) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "wineDF = spark.read.format(\"org.apache.spark.sql.cassandra\").options(table=\"wines\", keyspace=astraKeyspace).load()\n",
    "\n",
    "print (\"Table Wine Row Count: \")\n",
    "print (wineDF.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showDF(wineDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's filter out only wines that have been rated 6.0 or higher and create a new dataframe with that information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine6DF = wineDF.filter(\"quality > 5\")\n",
    "showDF(wine6DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Vector with all elements of the wine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols=['alcohol', 'chlorides', 'citricacid', 'density', 'fixedacidity', 'ph', 'freesulfur', 'sugar', 'sulphates', 'totalsulfur', 'volatileacidity'],\n",
    "    outputCol='features')\n",
    "\n",
    "trainingData = assembler.transform(wine6DF)\n",
    "\n",
    "labelIndexer = StringIndexer(inputCol=\"quality\", outputCol=\"label\", handleInvalid='keep')\n",
    "trainingData1 = labelIndexer.fit(trainingData).transform(trainingData)\n",
    "\n",
    "showDF(trainingData1)\n",
    "print(trainingData1.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will be training a model with Random Forest, and because of this we need to split up our dataset in to a training and test set. Will split 80/20. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test\n",
    "splits = trainingData1.randomSplit([0.8, 0.2], 1234)\n",
    "train = splits[0]\n",
    "test = splits[1]\n",
    "\n",
    "print (\"Train Dataframe Row Count: \")\n",
    "print (train.count())\n",
    "print (\"Test Datafram Row Count: \")\n",
    "print (test.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=10)\n",
    "\n",
    "model = rf.fit(train)\n",
    "\n",
    "predictions = model.transform(test)\n",
    "#predictions.show()\n",
    "print (predictions.count())\n",
    "showDF(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showDF(predictions.select(\"quality\", \"label\", \"prediction\", \"probability\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can now use the MutliclassClassifciationEvaluator to evalute the accurancy of our predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute accuracy on the test set\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
    "                                              metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test set accuracy = \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_wine_quality(**kwargs):\n",
    "    input_df = pandas.DataFrame([kwargs])\n",
    "    spark_input = spark.createDataFrame(input_df)\n",
    "    spark_with_features = assembler.transform(spark_input)\n",
    "    predicted = model.transform(spark_with_features)\n",
    "    collected = predicted.collect()\n",
    "    #\n",
    "    return {\n",
    "        'prediction': collected[0].prediction,\n",
    "        'probability': list(collected[0].probability),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_wine_quality(\n",
    "    alcohol = 15.0,\n",
    "    chlorides = 0.017,\n",
    "    citricacid = 0.31,\n",
    "    density = 0.99100,\n",
    "    fixedacidity = 5.1,\n",
    "    freesulfur = 12.0,\n",
    "    ph = 4.14,\n",
    "    sugar = 1.90,\n",
    "    sulphates = 0.50,\n",
    "    totalsulfur = 103.0,\n",
    "    volatileacidity = 0.170,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#session.execute(\"\"\"drop table wines\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
