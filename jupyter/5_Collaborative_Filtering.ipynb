{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/datastaxdevs_banner.png\" width=\"600\" height=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm 5: Collaborative Filtering\n",
    "------\n",
    "<img src=\"images/seinfeld.jpg\" width=\"400\" height=\"400\">\n",
    "\n",
    "#### Real Dataset: http://eigentaste.berkeley.edu/dataset/ Dataset 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are we trying to learn from this dataset?\n",
    "\n",
    "### Can Collaborative Filtering be used to find which jokes to recommend to our users?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from IPython.display import IFrame\n",
    "#\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql.functions import explode, col\n",
    "#\n",
    "#\n",
    "from cassandra.cluster import Cluster\n",
    "from cassandra.auth import PlainTextAuthProvider\n",
    "#\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "from tools import showDF, examineCassandraTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read .env file for connection params\n",
    "dotenv_file = find_dotenv('.env')\n",
    "load_dotenv(dotenv_file)\n",
    "astraUsername = os.environ['ASTRA_DB_CLIENT_ID']\n",
    "astraPassword = os.environ['ASTRA_DB_CLIENT_SECRET']\n",
    "astraSecureConnect = os.environ['ASTRA_DB_SECURE_BUNDLE_PATH']\n",
    "astraKeyspace = os.environ['ASTRA_DB_KEYSPACE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect input data: Table(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Cassandra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_config = {\n",
    "    'secure_connect_bundle': '/home/jovyan/' + astraSecureConnect\n",
    "}\n",
    "auth_provider = PlainTextAuthProvider(username=astraUsername, password=astraPassword)\n",
    "cluster = Cluster(cloud=cloud_config, auth_provider=auth_provider)\n",
    "session = cluster.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set keyspace "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.set_keyspace(astraKeyspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine table `jokes` (structure and contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(examineCassandraTable(session, astraKeyspace, 'jokes'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What do these 3 columns represent: \n",
    "\n",
    "* **Column 1**: User id\n",
    "* **Column 2**: Joke id\n",
    "* **Column 3**: Rating of joke (-10.00 - 10.00) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: the table contains a sample of 10'000 rows. The full dataset has over 1 _million_ rows.\n",
    "<img src=\"images/laughing.gif\" width=\"300\" height=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning with Apache Cassandra & Apache Spark\n",
    "<img src=\"images/sparklogo.png\" width=\"150\" height=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Spark session that is connected to the database. From there load each table into a Spark Dataframe and take a count of the number of rows in each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName('demo') \\\n",
    "    .master('local') \\\n",
    "    .config( \\\n",
    "        'spark.cassandra.connection.config.cloud.path', \\\n",
    "        'file:' + '/home/jovyan/' + astraSecureConnect) \\\n",
    "    .config('spark.cassandra.auth.username', astraUsername) \\\n",
    "    .config('spark.cassandra.auth.password', astraPassword) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "jokeTable = spark \\\n",
    "    .read \\\n",
    "    .format('org.apache.spark.sql.cassandra') \\\n",
    "    .options(table='jokes', keyspace=astraKeyspace) \\\n",
    "    .load()\n",
    "\n",
    "print ('Table Row Count:')\n",
    "print (jokeTable.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset into training and testing set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(training, test) = jokeTable.randomSplit([0.8, 0.2])\n",
    "\n",
    "training_df = training.withColumn('rating', training.rating.cast('int'))\n",
    "testing_df = test.withColumn('rating', test.rating.cast('int'))\n",
    "\n",
    "showDF(training_df, limitRows=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup for Collaborative Filtering with ALS (\"alternating least squares\")\n",
    "\n",
    "https://spark.apache.org/docs/latest/ml-collaborative-filtering.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "als = ALS(\n",
    "    maxIter=5,\n",
    "    regParam=0.2,\n",
    "    userCol='userid',\n",
    "    itemCol='jokeid',\n",
    "    ratingCol='rating',\n",
    "    coldStartStrategy='drop',\n",
    ")\n",
    "\n",
    "model = als.fit(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model by computing the RMSE on the test data\n",
    "test_results = model.transform(testing_df)\n",
    "showDF(test_results)\n",
    "\n",
    "evaluator = RegressionEvaluator(\n",
    "           metricName=\"rmse\", \n",
    "           labelCol=\"rating\", \n",
    "           predictionCol=\"prediction\") \n",
    "\n",
    "RMSE = evaluator.evaluate(test_results)\n",
    "print('RMSE = %.4f' % RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate top 10 joke recommendations for each user\n",
    "userRecs = model.recommendForAllUsers(10)\n",
    "\n",
    "showDF(userRecs, limitRows=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate top 10 user recommendations for each joke\n",
    "jokeRecs = model.recommendForAllItems(10)\n",
    "\n",
    "showDF(jokeRecs, limitRows=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check recommendations for a single user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is easier (for humans) than \"showDF(userRecs.filter(userRecs.userid == 65), limitRows=10)\"\n",
    "\n",
    "showDF(\n",
    "    userRecs.filter(userRecs.userid == 65) \\\n",
    "        .withColumn('recomm', explode('recommendations')) \\\n",
    "        .select('userid', col('recomm.jokeid'), col('recomm.rating')),\n",
    "    limitRows=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IFrame(src='images/init94.html', width=700, height=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IFrame(src='images/init43.html', width=700, height=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stop the Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
